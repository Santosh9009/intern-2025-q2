"""
Demo script to show the generate_tweet function structure and prompt formatting.
This script demonstrates the prompt engineering without making actual API calls.
"""

def demo_generate_tweet(topic: str, tone: str, max_words: int) -> str:
    """
    Demo version of generate_tweet that shows the prompt formatting
    without making actual LLM calls.
    """
    # Format prompt with variables - this is the key part for Q2
    prompt = f"Write a {tone} tweet about {topic} in under {max_words} words."
    
    print(f"Formatted Prompt: {prompt}")
    
    # In the real function, this would be sent to the LLM
    # For demo purposes, we'll return a mock response
    return f"[Mock Tweet] This would be a {tone} tweet about {topic} generated by the LLM"

def main():
    print("=== Q2: Prompt Template with Variables Demo ===\n")
    
    # Show how the prompt template works
    examples = [
        ("artificial intelligence", "funny", 25),
        ("climate change", "professional", 30),
        ("learning new skills", "inspiring", 20)
    ]
    
    for i, (topic, tone, max_words) in enumerate(examples, 1):
        print(f"Example {i}:")
        print(f"Input: generate_tweet('{topic}', '{tone}', {max_words})")
        result = demo_generate_tweet(topic, tone, max_words)
        print(f"Output: {result}\n")
    
    print("Key Features:")
    print("✅ Template variables: {topic}, {tone}, {max_words}")
    print("✅ F-string formatting for dynamic prompts")
    print("✅ Clear, structured prompt with specific instructions")
    print("✅ Parameterized function design")

if __name__ == "__main__":
    main()
